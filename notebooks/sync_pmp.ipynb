{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3, 4, 5, 6, 7\"\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as tt\n",
    "from torchvision import models\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "# define hyperparameters\n",
    "num_classes = 100\n",
    "num_epochs = 25\n",
    "batch_size = 16\n",
    "learning_rate = 0.005\n",
    "ngpu = 4\n",
    "parallelism = \"DataParallel\"\n",
    "weight_decay = 0.005\n",
    "momentum = 0.9\n",
    "\n",
    "wandb.init(\n",
    "    project=\"pmp_testing\",\n",
    "    config={\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"ngpu\": ngpu,\n",
    "        \"parallelism\": parallelism,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"momentum\": momentum,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something went wrong getting free gpus: \n"
     ]
    }
   ],
   "source": [
    "def get_free_gpus(threshold=10):\n",
    "    try:\n",
    "        # assert(torch.cuda.device_count() == 8)\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        utilizations = [int(x.strip()) for x in result.stdout.split('\\n') if x.strip()]\n",
    "        print(utilizations)\n",
    "\n",
    "        free_gpus = [i for i, util in enumerate(utilizations) if util < 10]\n",
    "        return free_gpus\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"something went wrong getting free gpus: {e}\")\n",
    "\n",
    "\n",
    "free_gpus = get_free_gpus()\n",
    "if free_gpus:\n",
    "    print(f\"Available GPUs are: {free_gpus}\")\n",
    "    selected_gpus = free_gpus[-ngpu:]\n",
    "    print(selected_gpus)\n",
    "\n",
    "    for gpu_idx in selected_gpus:\n",
    "        print(torch.cuda.device(gpu_idx))\n",
    "        print(torch.cuda.get_device_properties(gpu_idx))\n",
    "\n",
    "# device = torch.device(f\"cuda:{selected_gpus[0]}\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://pytorch.org/tutorials/intermediate/dist_tuto.html\n",
    "\n",
    "def run(rank, size):\n",
    "    \"\"\" Distributed function to be implemented later. \"\"\"\n",
    "    pass\n",
    "\n",
    "def init_process(rank, size, fn, backend='gloo'):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend, rank=rank, world_size=size)\n",
    "    fn(rank, size)\n",
    "\n",
    "\n",
    "world_size = ngpu\n",
    "processes = []\n",
    "mp.set_start_method(\"spawn\")\n",
    "for rank in range(world_size):\n",
    "    p = mp.Process(target=init_process, args=(rank, world_size, run))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def data_loader(data_dir,\n",
    "                batch_size,\n",
    "                random_seed=42,\n",
    "                valid_size=0.1,\n",
    "                shuffle=True,\n",
    "                test=False):\n",
    "  \n",
    "    normalize = tt.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    transform = tt.Compose([\n",
    "            tt.RandomCrop(32, padding=4,padding_mode='reflect'),\n",
    "            tt.RandomHorizontalFlip(),\n",
    "            tt.Resize((224,224)),\n",
    "            tt.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "\n",
    "    if test:\n",
    "        dataset = datasets.CIFAR100(\n",
    "          root=data_dir, train=False,\n",
    "          download=True, transform=transform,\n",
    "        )\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle\n",
    "        )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR100( root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    valid_dataset = datasets.CIFAR100(root=data_dir, train=True,download=True, transform=transform,)\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler, pin_memory=True)\n",
    " \n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler, pin_memory=True)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "\n",
    "# flower 102 dataset \n",
    "train_loader, valid_loader = data_loader(data_dir='./data',\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "test_loader = data_loader(data_dir='./data',\n",
    "                              batch_size=batch_size,\n",
    "                              test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get the model and examine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(progress=True, num_classes=100)#.to(device)\n",
    "# print(summary(model))\n",
    "# model.to(f\"cuda:{selected_gpus[0]}\")\n",
    "\n",
    "# if (device.type == 'cuda') and (ngpu > 1):\n",
    "#     model = nn.parallel.DistributedDataParallel(model, device_ids=selected_gpus)\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)  \n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [704/704], Loss: 4.3102\n",
      "Accuracy of the network on the 5000 validation images: 2.92 %\n",
      "Epoch [2/25], Step [704/704], Loss: 4.5064\n",
      "Accuracy of the network on the 5000 validation images: 4.44 %\n",
      "Epoch [3/25], Step [704/704], Loss: 4.2271\n",
      "Accuracy of the network on the 5000 validation images: 6.02 %\n",
      "Epoch [4/25], Step [704/704], Loss: 3.2166\n",
      "Accuracy of the network on the 5000 validation images: 11.36 %\n",
      "Epoch [5/25], Step [704/704], Loss: 3.7912\n",
      "Accuracy of the network on the 5000 validation images: 14.88 %\n",
      "Epoch [6/25], Step [704/704], Loss: 2.1552\n",
      "Accuracy of the network on the 5000 validation images: 17.56 %\n",
      "Epoch [7/25], Step [704/704], Loss: 3.4424\n",
      "Accuracy of the network on the 5000 validation images: 20.84 %\n",
      "Epoch [8/25], Step [704/704], Loss: 3.5063\n",
      "Accuracy of the network on the 5000 validation images: 18.32 %\n",
      "Epoch [9/25], Step [704/704], Loss: 2.1956\n",
      "Accuracy of the network on the 5000 validation images: 22.6 %\n",
      "Epoch [10/25], Step [704/704], Loss: 2.7161\n",
      "Accuracy of the network on the 5000 validation images: 24.56 %\n",
      "Epoch [11/25], Step [704/704], Loss: 1.8735\n",
      "Accuracy of the network on the 5000 validation images: 28.6 %\n",
      "Epoch [12/25], Step [704/704], Loss: 1.8105\n",
      "Accuracy of the network on the 5000 validation images: 28.64 %\n",
      "Epoch [13/25], Step [704/704], Loss: 1.4052\n",
      "Accuracy of the network on the 5000 validation images: 29.7 %\n",
      "Epoch [14/25], Step [704/704], Loss: 1.7965\n",
      "Accuracy of the network on the 5000 validation images: 30.92 %\n",
      "Epoch [15/25], Step [704/704], Loss: 1.7756\n",
      "Accuracy of the network on the 5000 validation images: 28.44 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) \n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmp10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
